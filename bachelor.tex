\documentclass[t]{beamer}
\input{premble.tex}

\usetheme{Madrid}
\usecolortheme{beaver}

\title{Bachelor forsvar}
\subtitle{En ISPC bagende til Futhark}
\author{Kristoffer A. Kortbaek}
\date{23. juni 2022}

%%Front page
\begin{document}
\begin{frame}
  \titlepage
\end{frame}

\begin{frame}[c]
  \frametitle{Fokuspunkt}

  \begin{enumerate}
    \item<+-> Multicore ``flattening''
    \item<+-> Udnyttelse af data parallelisme for \texttt{reduce}
    \item<+-> Hvordan påvirker multicore flattening de data parallelle SOACs
  \end{enumerate}
\end{frame}

%% Slide 1
\begin{frame}
MC IR indeholder to versioner af hver SOAC
  \frametitle{Multicore flattening background}
  \begin{figure}[H]
    \centering
    \includegraphics[height=0.7\textheight]{imgs/compileroverview.png}
  \end{figure}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Multicore flattening - sekventielle og parallelle SOACs}
  Et Futhark matrix-vector multiplication program kunne skrives som
  \begin{lstlisting}[language=futhark]
    def main m n  (X:[m][n]i32)  (v:[n]i32)  =
      map (\x ->
        reduce (+) 0 (map2 (*) x v)
      ) X
    \end{lstlisting}
  Programmet har ``nested'' parallelisme grundet den indre \texttt{reduce}
  \begin{enumerate}
    \begin{onlyenv}<2-2>
    \item Hver indre SOAC er blevet sekventialiseret
      \begin{lstlisting}[language=ispc, xleftmargin=-15mm]
        for(int map_i = 0; i < map_end; map_i++) {
          int red_res = 0; //Neutral element
          for(int red_i = 0;  red_end; red_i++) {
            int x = mem[map_i * n + red_i];
            int v_i = mem[red_i];
            int mul_res = x * v_i;
            red_res = mulres + red_res;
          }
          mem[map_i] = red_res;
        }
\end{lstlisting}
  \end{onlyenv}
    \begin{onlyenv}<3-3>
    \item De indre SOACs er uberørte og kører i parallel på flere kerner
      \begin{lstlisting}[language=ispc, xleftmargin=-15mm]
        //map
        for(int map_i = 0; i < map_end; map_i++) {
          // schedule work for the nested reduce
          mem[map_i] = reduce_res;
        }
        //reduce
        for(int red_i = 0;  red_end; red_i++) {
          int x = mem[map_i * n + red_i];
          int v_i = mem[red_i];
          int mul_res = x * v_i;
          red_res = mulres + red_res;
        }
      \end{lstlisting}
      \end{onlyenv}
  \end{enumerate}
  \only{Den nestede SOAC bliver kundt valgt hvis den ydre SOAC har færre iterationer end antal logiske kerne på CPUen}<4->
    %Hvis den ydre \texttt{map} indeholder flere iterationer end antal logiske kerner på CPUen sekventialiseres \texttt{reduce}

\end{frame}
\begin{frame}[fragile]
  \frametitle{Kan vi udnytte mere parallelisme?}
  \only{Brug ISPC til at udvide både de sekventielle og nestede SOACs}<+->
  \begin{enumerate}
    \item<+-> Hver tråds arbejde skal køre i ISPC - en såkaldt \textit{ISPC kernel}
    \item<+-> Benyt \texttt{foreach} hvor muligt
  \end{enumerate}
  \only{Vi prøvede forskellige måde at udnytte  language-c-quote til at generere selve ISPC koden}<+->
  \begin{enumerate}
    \item<+-> Genrer C kode og lav makroer i ISPC
          \begin{lstlisting}[language=ispc, xleftmargin=-20mm]
            #define auto uniform
          \end{lstlisting}
    \item<+-> Udvid language-c-quote med ISPC sprog konstruktioner
          \begin{lstlisting}[xleftmargin=-20mm]
            [C.cstm|foreach ($foreachiters:bounds) {$items:body}|]
          \end{lstlisting}
    \item<+-> Brug ecaped statements
          \begin{lstlisting}[xleftmargin=-20mm]
            [C.cstms|$escstm:("foreach (i=0 ... end)") { $items:body}|]
          \end{lstlisting}
  \end{enumerate}


\end{frame}

%% Slide 2

\begin{frame}
  \frametitle{Algoritmer til at udvide Futhark MC flattening}
  Hvordan kan man vektorisere de to forskellige versioner af en SOAC?
  \begin{enumerate}
    %\item Vores kodegenerator er ``dum'' omkring hvorvidt vi laver kode for en nested eller sekventialiseret SOAC
  % \item Begge versioner af en given SOAC kan tage gavn af data parallelisme
  % \item Vi udnytter et ekstra lag af parallelisme ved at lade hver tråd udnytte data parallelisme
  \item<+-> Giv hver SOAC en specifik vectoriseret algoritme afhængigt af operatoren
  \item<+-> Håndter scheduling fra ISPC
  \item<+-> Særligt har redomap fire forskellige kodegenereringer
    \begin{itemize}
    \item<+-> kommutative \texttt{reduce}
    \item<.> normal(ikke kommutative) \texttt{reduce}
    \item<.> \texttt{reduce} på en ``mapped'' operator
    \item<.> Ingen brug af vektorisering
    \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Kommutative reduktioner}
  \begin{block}{Kommutative Reduktioner genereres der særligt effektiv kode for}
  \begin{enumerate}
    \item Den binære operator kan ske i vilkårlig rækkefølge: $a + b = b + a$
          %Nævn at i vores rapport kalder vi det interleaved
    \item Hver \textit{program instance} kan arbejde på sit eget segment af inputtet
  \end{enumerate}
\end{block}
\begin{onlyenv}<+->
  Simple reduktion over input array
  \begin{columns}
  \column{0.49\textwidth}
  \begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{imgs/input.png}
\end{figure}
\column{0.49\textwidth}

  \begin{lstlisting}[language=futhark]
    reduce (+) 0 as
  \end{lstlisting}

\end{columns}
\end{onlyenv}
\begin{onlyenv}<+->
  Den vectoriserede algoritme for kommutative \texttt{redomap}s har 2 skridt
  \begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{imgs/kom_reduction.png}
  \end{figure}
\end{onlyenv}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Kommutativ reduction 1}
  Hver program instance laver sin egen reduktion.
\begin{lstlisting}[language=ispc]
    int acc = 0;
    uniform int uni_acc = 0;
    foreach(Reduce_i = 0 ... n) {
      int a = mem[Reduce_i];
      int res = acc + a;
      acc = res;
    }
\end{lstlisting}
  \begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{imgs/kom_reduce1.png}
  \end{figure}
  \begin{center}
  \end{center}
\end{frame}
\begin{frame}[fragile]
  \frametitle{Kommutativ reduction 2}
  Derefter reduceres over resultaterne produceret af et \textit{gang}
  \begin{lstlisting}[language=ispc]
    forneach_active{i = 0 ... programCount} {
      uniform int a = extract(acc, i);
      uniformint res = uni_acc + a
      uni_acc = res;
    }
    mem_out[out] = uni_acc;
\end{lstlisting}
  \begin{figure}[H]
    \centering
    \includegraphics[width=0.25\textwidth]{imgs/kom_reduce2.png}
  \end{figure}
  %Nævn der ikke er en garanti for rækkefølgen af program instansernes operatioenr
\end{frame}

\begin{frame}
  \frametitle{Kommutativ reduktion restriktion}
  Vi har yderst god udnyttelse af SIMD
  \begin{enumerate}
    \item<+-> Hver program instance kører hele tiden
  \end{enumerate}
  \only{Vi kan dog se at der ikke er garanti for rækkefølgen af reduktionen}<+->
  \begin{enumerate}
    \item<+-> Den ene program instance regner $2+4+6+8$
    \item<+-> Den anden regner $1+3+5+7$
  \end{enumerate}
  Derved bliver vi nødt til at håndtere generelle associative operatorer anderledes
\end{frame}

\begin{frame}[fragile]
  \frametitle{Associative redomap}
  \begin{onlyenv}<+->
    \begin{block}{Associative reduktioner leder til delvis SIMD udnyttelse}
      \begin{enumerate}
        \item Den binære operator skal påføres i specifik rækkefølge
        \item Vi kan ikke lade hver \textit{program instance} arbejde på sit eget segment
        \item Mapping functionen bliver vektoriseret og selve \texttt{reduce} kører sekventielt
      \end{enumerate}
    \end{block}
  \end{onlyenv}
  \begin{onlyenv}<+->
    Vi håndterer korrekt nested parallelisme og sekventialiserede SOACs ved at \textit{sekventialisere} selve \texttt{reduce} operatoren
\begin{lstlisting}[language=ispc]
    uniform int scalar_accum = neutral;
    foreach (i = 0 ... size) {
      int elem_i = arr[i];
      int mapped = map_op(elem_i);
      foreach_active (j) {
        uniform int elem_j = extract(mapped, j);
        scalar_accum = reduce_op(scalar_accum, elem_j); }
    }
    return scalar_accum;
\end{lstlisting}
  \end{onlyenv}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Redomap på en \textit{mapped} operator}
  \begin{onlyenv}<+->
    \begin{block}{Mapped operator}
      \begin{enumerate}
        \item En \texttt{reduce} eller \texttt{scan} med en \texttt{map2} som operator
        \item Særtilfælde hvor operatoren er på arrays, og vi generer ISPC kode
      \end{enumerate}
    \end{block}
  \end{onlyenv}
  % \begin{block}{Mapped operator er et særtilfælde af der handles effektivt}
  %   \begin{enumerate}
  %   \item Særtilfælde der kan håndterer operatorer der tager arrays
  %   \item Håndteres ofte effektivit da vi kan vektorisere den indre operator
  %   \end{enumerate}
  % \end{block}
  \begin{onlyenv}<+->
    Simpelt program der tager en \textit{mapped} operator i form af \texttt{map2}
\begin{lstlisting}[language=futhark]
  entry mapped_plus [m][n] (X: [m][n]f32) =
    let a = replicate n 0
    in reduce (map2 (f32.min)) a X

\end{lstlisting}
  \end{onlyenv}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Redomap \textit{mapped} operator eksempel}
  \begin{center}
  \only<+>{\includegraphics[width=0.7\textwidth]{imgs/mapped1}}
  \only<+>{\includegraphics[width=0.7\textwidth]{imgs/mapped2}}
  \only<+>{\includegraphics[width=0.7\textwidth]{imgs/mapped3}}
  \only<+>{\includegraphics[width=0.7\textwidth]{imgs/mapped4}}
  \only<+>{\includegraphics[width=0.7\textwidth]{imgs/mapped5}}
  \end{center}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Redomap \textit{mapped} operator algoritme}
  Observationer
  \begin{enumerate}
    \item<+-> Applikationen af $+$ er uafhængig af \texttt{map2} loop iterationer
    \item<+-> Derved kan man lade $+$ kører ``på tværs'' af hvert \texttt{reduce} loop iterationer
    \item<+-> Vi kan derved vektorisere selve den \textit{mapped} operator \texttt{map2} sikkert
  \end{enumerate}
  \begin{onlyenv}<+->
    \begin{block}{redomap med en mapped operator}
\begin{lstlisting}[language=ispc]
      uniform int acc_mem[m] = //some memory
      for(uniform int red_i = 0; scan_i < i; sca_i++) {
        foreach(nest_i = 0 ... m) {
          x_acc = acc_mem[nest_i];
          x = mem[red_i * n + nest_i];
          int res = x_acc + x;
          acc_mem[nest_i] = res;
        }
      }
\end{lstlisting}
    \end{block}
  \end{onlyenv}
  \end{frame}

%% Slide 3
\begin{frame}[fragile]
  \frametitle{Konklusion}
  Er vores algoritmer en god udvidelse af MC flattening?
  \begin{enumerate}
    \item<+-> Sekventialiserede SOACs giver oftte \textit{scatter} og \textit{gather} operationer\\
      \begin{onlyenv}<+-3>
        Matrix vector multiplication programmet
      \begin{columns}
        \begin{column}{0.49\textwidth}
        \begin{lstlisting}[language=ispc, xleftmargin=-15mm, breaklines=false]
        //Sekventialiseret
        foreach(map_i = 0 ... end) {
          for(int red_i = 0) {
            x = mem[map_i * n + red_i];
          }
        }
\end{lstlisting}
        \end{column}
        \begin{column}{0.49\textwidth}
        \begin{lstlisting}[language=ispc, xleftmargin=-15mm, breaklines=false]
        //Nested reduce
        for(red_i = 0 ... end) {
          x = mem[map_i * n + red_i];
        }
\end{lstlisting}
          \end{column}
    \end{columns}
  \end{onlyenv}

  \begin{onlyenv}<+>
    \begin{table}[H]
      \begin{tabular}{|l|l|l|l|l|}
      \hline
      Benchmark                                                  &  & Multicore (ms) & Ours (ms) & Speedup \\ \cline{1-1} \cline{3-5}
      \begin{tabular}[c]{@{}l@{}}$m=100, n=100000$\end{tabular} &  & 1              & 3         & x0.44   \\ \cline{1-1} \cline{3-5}
      \begin{tabular}[c]{@{}l@{}}$m=6, n=10000000$\end{tabular} &  & 12             & 12        & x0.97   \\ \hline
      \end{tabular}
    \end{table}
  \end{onlyenv}

    % \item<+-> Dårlig cache lokalitet ved sekventialiserede SOACs. %lav lige issmalle over i C
    %       \begin{onlyenv}<+>
    %         \begin{table}[H]
    %           \begin{tabular}{ll|llll|}
    %             \cline{3-6}
    %             &  & \multicolumn{4}{l|}{Program instance}                                                    \\ \hline
    %             \multicolumn{1}{|l|}{red\_i} &  & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{1}    & \multicolumn{1}{l|}{2}      & 3     \\ \cline{1-1} \cline{3-6}
    %             \multicolumn{1}{|l|}{0}      &  & \multicolumn{1}{l|}{0} & \multicolumn{1}{l|}{5220} & \multicolumn{1}{l|}{10440}  & 15660 \\ \cline{1-1} \cline{3-6}
    %             \multicolumn{1}{|l|}{1}      &  & \multicolumn{1}{l|}{1} & \multicolumn{1}{l|}{5221} & \multicolumn{1}{l|}{10441}  & 15661 \\ \cline{1-1} \cline{3-6}
    %             \multicolumn{1}{|l|}{2}      &  & \multicolumn{1}{l|}{2} & \multicolumn{1}{l|}{5222} & \multicolumn{1}{l|}{10442}  & 15662 \\ \cline{1-1} \cline{3-6}
    %             \multicolumn{1}{|l|}{3}      &  & \multicolumn{1}{l|}{3} & \multicolumn{1}{l|}{5223} & \multicolumn{1}{l|}{10443,} & 15663 \\ \hline
    %           \end{tabular}
    %         \end{table}
    %       \end{onlyenv}
    \item<+-> Undersøge muligheden for kun og vektorisere den inderste SOAC ved sekventialiserede SOACs
          \begin{onlyenv}<+>
\begin{lstlisting}[language=futhark]
entry mapped_plus [m][n] (X: [m][n]f32) =
  let a = replicate n 0
  in reduce (map2 (f32.min)) a X
\end{lstlisting}
          \end{onlyenv}
  \begin{onlyenv}<+>
   \begin{lstlisting}[language=ispc, xleftmargin=-15mm]
         uniform int acc_mem[m] = //some memory
         for(uniform int red_i = 0; scan_i < i; sca_i++) {
           foreach(nest_i = 0 ... m) {
             x_acc = acc_mem[nest_i];
             x = mem[red_i * n + nest_i];
             int res = x_acc + x;
             acc_mem[nest_i] = res;
           }
         }
\end{lstlisting}
\begin{table}[H]
\begin{tabular}{|l|l|l|l|l|}
\hline
Benchmark                                                  &  & Multicore (ms) & Ours (ms) & Speedup \\ \cline{1-1} \cline{3-5}
\begin{tabular}[c]{@{}l@{}}$m=1000000, n=100$\end{tabular} &  & 31             & 11        & x2.83   \\ \cline{1-1} \cline{3-5}
\begin{tabular}[c]{@{}l@{}}$m=100, n=1000000$\end{tabular} &  & 88             & 81        & x1.08   \\ \hline
\end{tabular}
\end{table}

  \end{onlyenv}

    \item<+-> Vi har på en let måde fået ekstra speedup på multicore bagenden uden at ændre tidligere stadier af compileren
    \item<+-> Identificeret steder hvor vi kan lave forbedringer til compileren, for at gøre memory accesses hurtigere
  \end{enumerate}
\end{frame}
\end{document}
